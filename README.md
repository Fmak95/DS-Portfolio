# Data-Science-Portfolio by Freeman Mak

This portfolio is a compilation of notebooks which I created for data analysis or for exploration of machine learning algorithms.

# Regression Problems
## Caterpillar Tube Pricing (In Progress...)
<a href="https://github.com/Fmak95/Caterpillar-Tube-Pricing/blob/master/Caterpillar_Tubes_Pricing.ipynb">Github</a>

This challenge was issued by Caterpillar: given a dataset containing multiple CSV files that contained information pertaining tube assemblies, predict their price. General description and data are available on <a href="https://www.kaggle.com/c/caterpillar-tube-pricing">Kaggle</a>. Dataset consists of many files, so there is an additional challenge in combining the data and selecting the features.

## House Prices: Advanced Regression Techniques
<a href="https://github.com/Fmak95/House-Prices-Advanced-Regression-Techniques/blob/master/House_Prices.ipynb">Github</a>

A classic machine learning problem: based on a variety of household features, predict the price of the house. General description and data are available on <a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques">Kaggle</a>. The dataset has a lot of features and many missing values. This gives interesting possibilities for feature transformation, data visualization, feature engineering and data imputation techniques.

# Classification Problems
## CareerCon 2019 - Help Navigate Robots
<a href="https://github.com/Fmak95/CareerCon-2019/blob/master/CareerCon_2019.ipynb">Github</a>

This was a recruitment competition on <a href="https://www.kaggle.com/c/career-con-2019">Kaggle</a>. Unfortunately I entered this competition after the deadline, but I still completed the challenge for some extra practice! Given IMU sensor information on robots, we were asked to determine the surface in which the robot was traversing on (carpet, wood, concrete...). I played around with a deep learning approach, tackling the problem with a fully connected, multi layer neural network. I also used some model evaluation techniques: cross-validation, precision/recall scores.

## Titanic: Machine Learning from Disaster
<a href="https://github.com/Fmak95/Titanic-Machine-Learning-From-Disaster/blob/master/Titanic.ipynb">Github</a>

Titanic: Machine Learning from Disaster is a knowledge competition on Kaggle. Many people started practicing in machine learning with this competition, so did I. This is a binary classification problem: based on information about Titanic passengers we predict whether they survived or not. General description and data are available on <a href="https://www.kaggle.com/c/titanic/overview">Kaggle</a>. Titanic dataset provides interesting opportunities for feature engineering.

## Digit Recognizer
<a href="https://github.com/Fmak95/DigitRecognizer/blob/master/DigitRecognizer.ipynb">Github</a>

This was a competition on <a href="https://www.kaggle.com/c/digit-recognizer">Kaggle</a> in which we tried to recognize handwritten digits. This competition provided experience with convolutional neural networks and classical computer vision techniques. 

# Natural Language Processing:
## Bag of Words Meets Bag of Popcorn
<a href="https://github.com/Fmak95/Bag-of-words-meet-bag-of-popcorn/tree/master/Notebooks">Github</a>

In this notebook we try to identify if a movie review is positive or negative. This notebook gave me lots of experience with word modelling (Bag of Words, Word Vectors, idf) as well as deep learning practice (RNNs and LSTMs).
